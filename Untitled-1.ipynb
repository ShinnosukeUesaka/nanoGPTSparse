{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True, False, False,  True,  True, False, False,  True],\n",
      "        [False,  True, False, False,  True, False,  True, False, False,  True],\n",
      "        [ True,  True, False,  True, False, False, False,  True,  True, False],\n",
      "        [ True, False, False,  True, False,  True, False, False,  True,  True],\n",
      "        [ True,  True,  True, False, False, False, False, False,  True, False],\n",
      "        [False, False, False, False,  True,  True,  True, False, False,  True],\n",
      "        [False, False,  True, False, False, False, False,  True,  True, False],\n",
      "        [ True, False, False,  True, False,  True, False,  True, False, False],\n",
      "        [False,  True, False,  True,  True, False, False, False,  True, False],\n",
      "        [ True, False,  True, False,  True, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = torch.rand(10, 10)\n",
    "\n",
    "mask_a = torch.rand_like(X)\n",
    "mask_a = mask_a.ge(0.5)\n",
    "print(mask_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.rand(10, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1288, 0.9066, 0.3143],\n",
       "        [0.7318, 0.9672, 0.1538],\n",
       "        [0.7276, 0.2354, 0.6531],\n",
       "        [0.6529, 0.1535, 0.8629],\n",
       "        [0.0714, 0.4981, 0.1789],\n",
       "        [0.8557, 0.1552, 0.5176],\n",
       "        [0.6626, 0.9216, 0.4784],\n",
       "        [0.5608, 0.9467, 0.4124],\n",
       "        [0.5333, 0.6076, 0.4556],\n",
       "        [0.3093, 0.9140, 0.4340],\n",
       "        [0.2436, 0.8682, 0.0990],\n",
       "        [0.8412, 0.0870, 0.5808],\n",
       "        [0.3111, 0.4664, 0.3546],\n",
       "        [0.3804, 0.4471, 0.9116],\n",
       "        [0.4680, 0.5627, 0.1405],\n",
       "        [0.5148, 0.9714, 0.1687],\n",
       "        [0.7192, 0.7716, 0.4860],\n",
       "        [0.1375, 0.0431, 0.4704],\n",
       "        [0.4733, 0.5111, 0.7632],\n",
       "        [0.1423, 0.7691, 0.3122],\n",
       "        [0.9224, 0.6215, 0.8683],\n",
       "        [0.9546, 0.7045, 0.3180],\n",
       "        [0.4011, 0.1501, 0.2771],\n",
       "        [0.2147, 0.4081, 0.9959],\n",
       "        [0.5356, 0.2339, 0.0254],\n",
       "        [0.1723, 0.8022, 0.2259],\n",
       "        [0.3222, 0.6391, 0.6445],\n",
       "        [0.2606, 0.4353, 0.4512],\n",
       "        [0.3062, 0.8533, 0.2981],\n",
       "        [0.7564, 0.7741, 0.2288],\n",
       "        [0.7375, 0.7516, 0.2246],\n",
       "        [0.3679, 0.9527, 0.0409],\n",
       "        [0.3607, 0.0013, 0.2571],\n",
       "        [0.9472, 0.4141, 0.8861],\n",
       "        [0.7095, 0.8235, 0.4166],\n",
       "        [0.0251, 0.9170, 0.8885],\n",
       "        [0.5691, 0.5400, 0.0872],\n",
       "        [0.9019, 0.5744, 0.1646],\n",
       "        [0.5258, 0.5263, 0.7230],\n",
       "        [0.6175, 0.5214, 0.2161],\n",
       "        [0.9510, 0.1973, 0.1923],\n",
       "        [0.3465, 0.6859, 0.6385]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[mask_a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.rand(2, 10, 3)\n",
    "mask_a = torch.randn(2, 10)\n",
    "mask_a = mask_a.ge(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False, False, False,  True, False, False,  True,  True],\n",
       "        [ True,  True,  True, False, False, False, False,  True, False,  True]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_a = tokens[mask_a]\n",
    "tokens_b = tokens[~mask_a]\n",
    "tokens_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2153, 0.6650, 0.6310],\n",
       "        [0.8491, 0.5278, 0.0519],\n",
       "        [0.2147, 0.4110, 0.3565],\n",
       "        [0.7949, 0.0803, 0.0153],\n",
       "        [0.9287, 0.7804, 0.1306],\n",
       "        [0.1494, 0.2404, 0.0793],\n",
       "        [0.8190, 0.2129, 0.4175],\n",
       "        [0.2518, 0.3553, 0.6550],\n",
       "        [0.0174, 0.2028, 0.5313],\n",
       "        [0.3640, 0.7408, 0.8255]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.1526e-01, 6.6496e-01, 6.3104e-01],\n",
       "         [8.4913e-01, 5.2782e-01, 5.1911e-02],\n",
       "         [1.5153e-02, 7.6409e-01, 6.2610e-01],\n",
       "         [1.9551e-01, 3.4796e-01, 4.6703e-01],\n",
       "         [2.2721e-01, 6.2438e-01, 9.3349e-01],\n",
       "         [2.1466e-01, 4.1101e-01, 3.5652e-01],\n",
       "         [2.2361e-02, 9.0319e-01, 9.4424e-01],\n",
       "         [5.8645e-04, 2.7227e-01, 4.8529e-01],\n",
       "         [7.9486e-01, 8.0260e-02, 1.5291e-02],\n",
       "         [9.2866e-01, 7.8038e-01, 1.3059e-01]],\n",
       "\n",
       "        [[1.4944e-01, 2.4042e-01, 7.9284e-02],\n",
       "         [8.1905e-01, 2.1286e-01, 4.1755e-01],\n",
       "         [2.5179e-01, 3.5531e-01, 6.5501e-01],\n",
       "         [6.4613e-01, 4.7757e-01, 7.0226e-01],\n",
       "         [9.1380e-01, 4.6045e-01, 2.2548e-01],\n",
       "         [6.2557e-01, 3.8946e-01, 9.4441e-02],\n",
       "         [6.6155e-01, 9.5674e-01, 1.1765e-01],\n",
       "         [1.7388e-02, 2.0285e-01, 5.3132e-01],\n",
       "         [1.0723e-01, 3.6570e-01, 8.3088e-01],\n",
       "         [3.6401e-01, 7.4077e-01, 8.2547e-01]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T = mask_a.size()\n",
    "C = tokens_a.size(-1)\n",
    "\n",
    "interleaved = torch.zeros(B, T, C, device=tokens_a.device, dtype=tokens_a.dtype)\n",
    "flattend_text_mask = mask_a.view(-1)\n",
    "interleaved.view(-1, C)[flattend_text_mask] = tokens_a.view(-1, C)\n",
    "interleaved.view(-1, C)[~flattend_text_mask] = tokens_b.view(-1, C)\n",
    "interleaved = interleaved.contiguous()\n",
    "interleaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.1526e-01, 6.6496e-01, 6.3104e-01],\n",
       "         [8.4913e-01, 5.2782e-01, 5.1911e-02],\n",
       "         [1.5153e-02, 7.6409e-01, 6.2610e-01],\n",
       "         [1.9551e-01, 3.4796e-01, 4.6703e-01],\n",
       "         [2.2721e-01, 6.2438e-01, 9.3349e-01],\n",
       "         [2.1466e-01, 4.1101e-01, 3.5652e-01],\n",
       "         [2.2361e-02, 9.0319e-01, 9.4424e-01],\n",
       "         [5.8645e-04, 2.7227e-01, 4.8529e-01],\n",
       "         [7.9486e-01, 8.0260e-02, 1.5291e-02],\n",
       "         [9.2866e-01, 7.8038e-01, 1.3059e-01]],\n",
       "\n",
       "        [[1.4944e-01, 2.4042e-01, 7.9284e-02],\n",
       "         [8.1905e-01, 2.1286e-01, 4.1755e-01],\n",
       "         [2.5179e-01, 3.5531e-01, 6.5501e-01],\n",
       "         [6.4613e-01, 4.7757e-01, 7.0226e-01],\n",
       "         [9.1380e-01, 4.6045e-01, 2.2548e-01],\n",
       "         [6.2557e-01, 3.8946e-01, 9.4441e-02],\n",
       "         [6.6155e-01, 9.5674e-01, 1.1765e-01],\n",
       "         [1.7388e-02, 2.0285e-01, 5.3132e-01],\n",
       "         [1.0723e-01, 3.6570e-01, 8.3088e-01],\n",
       "         [3.6401e-01, 7.4077e-01, 8.2547e-01]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.1526e-01, 6.6496e-01, 6.3104e-01],\n",
       "         [8.4913e-01, 5.2782e-01, 5.1911e-02],\n",
       "         [1.5153e-02, 7.6409e-01, 6.2610e-01],\n",
       "         [1.9551e-01, 3.4796e-01, 4.6703e-01],\n",
       "         [2.2721e-01, 6.2438e-01, 9.3349e-01],\n",
       "         [2.1466e-01, 4.1101e-01, 3.5652e-01],\n",
       "         [2.2361e-02, 9.0319e-01, 9.4424e-01],\n",
       "         [5.8645e-04, 2.7227e-01, 4.8529e-01],\n",
       "         [7.9486e-01, 8.0260e-02, 1.5291e-02],\n",
       "         [9.2866e-01, 7.8038e-01, 1.3059e-01]],\n",
       "\n",
       "        [[1.4944e-01, 2.4042e-01, 7.9284e-02],\n",
       "         [8.1905e-01, 2.1286e-01, 4.1755e-01],\n",
       "         [2.5179e-01, 3.5531e-01, 6.5501e-01],\n",
       "         [6.4613e-01, 4.7757e-01, 7.0226e-01],\n",
       "         [9.1380e-01, 4.6045e-01, 2.2548e-01],\n",
       "         [6.2557e-01, 3.8946e-01, 9.4441e-02],\n",
       "         [6.6155e-01, 9.5674e-01, 1.1765e-01],\n",
       "         [1.7388e-02, 2.0285e-01, 5.3132e-01],\n",
       "         [1.0723e-01, 3.6570e-01, 8.3088e-01],\n",
       "         [3.6401e-01, 7.4077e-01, 8.2547e-01]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interleaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x1e\\x00O\\x00G\\x00F\\x00K\\x00C\\x00Y\\x00K\\x00M\\x00K\\x00\\x02\\x00Z\\x00O\\x00N\\x00P\\x00U\\x00\\x1f\\x00\\x04\\x00J\\x00V\\x00V\\x00R\\x00\\x1c\\x00\\x11\\x00\\x11\\x00Y\\x00Y\\x00Y\\x00\\x10\\x00O\\x00G\\x00F\\x00K\\x00C\\x00Y\\x00K\\x00M\\x00K\\x00\\x10\\x00Q\\x00T\\x00I\\x00\\x11\\x00Z\\x00O\\x00N\\x00\\x11\\x00G\\x00Z\\x00R\\x00'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "with open(\"data/enwik8_char/train.bin\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "    #data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
    "data[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.frombuffer(data, dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 79, 71, ..., 80, 69, 71], shape=(89659648,), dtype=uint16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pickle\n",
    "meta_path = \"data/enwik8_char/meta.pkl\"\n",
    "with open(meta_path, 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "# TODO want to make this more general to arbitrary encoder/decoder schemes\n",
    "stoi, itos = meta['stoi'], meta['itos']\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<me'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([30, 79, 71])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([54, 74, 71,  2, 89, 81, 84, 70,  2,  9,  9,  9, 67, 80, 67, 84, 69, 74,\n",
       "        75, 85, 79,  9,  9,  9,  2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor(encode(\"The word '''anarchism''' \"))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True, False, False, False, False,  True, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tensor([x in [1,2,5] for x in X])\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54,\n",
       " 74,\n",
       " 71,\n",
       " 2,\n",
       " 89,\n",
       " 81,\n",
       " 84,\n",
       " 70,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 67,\n",
       " 80,\n",
       " 67,\n",
       " 84,\n",
       " 69,\n",
       " 74,\n",
       " 75,\n",
       " 85,\n",
       " 79,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 2]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"The word '''anarchism''' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.uint16' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m      6\u001b[0m stoi, itos \u001b[38;5;241m=\u001b[39m meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstoi\u001b[39m\u001b[38;5;124m'\u001b[39m], meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitos\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m encode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m s: [stoi[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m s]\n\u001b[0;32m----> 8\u001b[0m decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m l: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([itos[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m l])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.uint16' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"{i}: {decode(data[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = \"data/enwik8_char\"\n",
    "block_size = 256\n",
    "batch_size = 32\n",
    "device_type = 'mps'\n",
    "device = 'mps'\n",
    "\n",
    "def get_batch(split, load_mask=False):\n",
    "    # We recreate np.memmap every batch to avoid a memory leak, as per\n",
    "    # https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122\n",
    "    if split == 'train':\n",
    "        data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
    "        mask = np.memmap(os.path.join(data_dir, 'train_mask.bin'), dtype=np.uint8, mode='r') if load_mask else None\n",
    "    else:\n",
    "        data = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint16, mode='r')\n",
    "        mask = np.memmap(os.path.join(data_dir, 'val_mask.bin'), dtype=np.uint8, mode='r') if load_mask else None\n",
    "\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
    "    if load_mask:\n",
    "        mask = torch.stack([torch.from_numpy((mask[i:i+block_size]).astype(np.bool_)) for i in ix])\n",
    "\n",
    "    if device_type == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "    if load_mask:\n",
    "        return x, y, mask\n",
    "    else:\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False,  True,  ...,  True,  True,  True],\n",
       "        [False,  True,  True,  ...,  True, False,  True],\n",
       "        [ True,  True,  True,  ..., False,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True, False,  ..., False,  True,  True],\n",
       "        [False, False, False,  ..., False, False,  True],\n",
       "        [ True,  True, False,  ..., False,  True,  True]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, mask = get_batch('train', load_mask=True)\n",
    "x.shape, y.shape, mask.shape\n",
    "mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True, False, False, False, False, False, False, False, False,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False, False, False,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True, False, False, False,\n",
       "        False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False, False,  True,  True,  True,  True, False, False, False,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True, False,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False, False,  True,  True,  True, False,\n",
       "        False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        False, False, False, False,  True,  True,  True,  True, False, False,\n",
       "        False,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True, False, False,  True,  True,\n",
       "         True, False,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"w.culpa.info.]]\\n\\n=== Publications===\\nMajor publications include The ''[[Columbia Review]]'',[http://www.columbia.edu/cu/review] the nation's oldest college literary magazine ; The ''[[Columbia Daily Spectator]]'',[http://www.columbiaspectator.com] the nati\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(x[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1019)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "input = torch.tensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n",
    "target = torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype=torch.float)\n",
    "output = loss(input, target)\n",
    "output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[179,  74, 108, 241,  31, 165,  53, 104,  18, 131, 112, 217,  46, 251,\n",
      "         217, 252],\n",
      "        [119, 171,  90, 124, 159,  53, 247,  53, 142,  11, 173,  30, 146,  28,\n",
      "         205, 156]])\n",
      "y: tensor([[ 74, 108, 241,  31, 165,  53, 104,  18, 131, 112, 217,  46, 251, 217,\n",
      "         252,  92],\n",
      "        [171,  90, 124, 159,  53, 247,  53, 142,  11, 173,  30, 146,  28, 205,\n",
      "         156, 173]])\n",
      "mask_a: tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "from model import SparseGPT, SparseGPTConfig\n",
    "import torch\n",
    "config = SparseGPTConfig(\n",
    "    block_size=16,\n",
    "    vocab_size=256,\n",
    "    n_layer=1,\n",
    "    n_head=2,\n",
    "    n_embd_a=8,\n",
    "    n_embd_b=8,\n",
    "    n_embd_attention=8,\n",
    "    dropout=0.0,\n",
    "    bias=False\n",
    ")\n",
    "x = torch.randint(0, 257, (2, 17))\n",
    "y = x[:, 1:]\n",
    "x = x[:, :-1]\n",
    "mask_a = torch.randn(2, 16)\n",
    "mask_a = mask_a.ge(-100)\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")\n",
    "print(f\"mask_a: {mask_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.00M\n"
     ]
    }
   ],
   "source": [
    "from model_old import GPT, GPTConfig\n",
    "gpt_config = GPTConfig(\n",
    "    block_size=16,\n",
    "    vocab_size=256,\n",
    "    n_layer=1,\n",
    "    n_head=2,\n",
    "    n_embd=8,\n",
    ")\n",
    "gpt_model = GPT(gpt_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.01M\n"
     ]
    }
   ],
   "source": [
    "model = SparseGPT(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 16]), torch.Size([2, 16]), torch.Size([2, 16]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, mask_a.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_x = x[:, :-1].contiguous()\n",
    "smaller_y = y[:, :-1].contiguous()\n",
    "smaller_mask_a = mask_a[:, :-1].contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_a: tensor([[-0.0269,  0.0067, -0.0262,  0.0040,  0.0176, -0.0387,  0.0145,  0.0043],\n",
      "        [ 0.0308, -0.0302, -0.0117,  0.0023,  0.0023,  0.0229, -0.0437,  0.0015],\n",
      "        [ 0.0349,  0.0124,  0.0028,  0.0099, -0.0156, -0.0413,  0.0263, -0.0152],\n",
      "        [ 0.0394,  0.0131,  0.0221, -0.0006, -0.0446, -0.0309,  0.0073, -0.0035],\n",
      "        [ 0.0177,  0.0008,  0.0347,  0.0450,  0.0025,  0.0206,  0.0017,  0.0077],\n",
      "        [ 0.0374, -0.0081,  0.0181, -0.0004, -0.0102, -0.0009, -0.0017,  0.0089],\n",
      "        [-0.0290,  0.0462, -0.0017, -0.0056,  0.0136, -0.0115, -0.0127,  0.0279],\n",
      "        [ 0.0312, -0.0281,  0.0193, -0.0206,  0.0627,  0.0084,  0.0006, -0.0094],\n",
      "        [-0.0577, -0.0155,  0.0171,  0.0011, -0.0257, -0.0103,  0.0268,  0.0054],\n",
      "        [-0.0076,  0.0290,  0.0289, -0.0381,  0.0088, -0.0141, -0.0454,  0.0172],\n",
      "        [-0.0384, -0.0253,  0.0104,  0.0136,  0.0087, -0.0164,  0.0033, -0.0356],\n",
      "        [-0.0013, -0.0084, -0.0589,  0.0126,  0.0011,  0.0183,  0.0144,  0.0172],\n",
      "        [-0.0096, -0.0215,  0.0417,  0.0044, -0.0113, -0.0227, -0.0135, -0.0238],\n",
      "        [-0.0208,  0.0089,  0.0560, -0.0113,  0.0250, -0.0491, -0.0062, -0.0190],\n",
      "        [-0.0047,  0.0289, -0.0419,  0.0093,  0.0114,  0.0261,  0.0318,  0.0089],\n",
      "        [ 0.0096, -0.0183, -0.0129,  0.0102,  0.0179, -0.0546, -0.0336,  0.0091],\n",
      "        [ 0.0296, -0.0238, -0.0051,  0.0231,  0.0117, -0.0054, -0.0421, -0.0343],\n",
      "        [ 0.0156, -0.0347,  0.0258,  0.0563,  0.0221, -0.0171, -0.0188, -0.0359],\n",
      "        [ 0.0341,  0.0201,  0.0200, -0.0071, -0.0177, -0.0511, -0.0352,  0.0333],\n",
      "        [ 0.0012,  0.0427,  0.0323,  0.0321, -0.0147,  0.0172, -0.0141, -0.0057],\n",
      "        [ 0.0150, -0.0047,  0.0345, -0.0022,  0.0016,  0.0065, -0.0172,  0.0279],\n",
      "        [-0.0437,  0.0511, -0.0304,  0.0053,  0.0083, -0.0291,  0.0223,  0.0145],\n",
      "        [ 0.0294,  0.0242,  0.0461, -0.0349,  0.0271, -0.0004, -0.0209,  0.0427],\n",
      "        [-0.0305, -0.0213, -0.0199,  0.0136,  0.0209,  0.0015, -0.0016,  0.0199],\n",
      "        [-0.0090, -0.0126,  0.0283,  0.0020,  0.0128,  0.0057, -0.0070,  0.0361],\n",
      "        [-0.0231, -0.0112,  0.0073,  0.0051, -0.0060, -0.0041,  0.0163,  0.0018],\n",
      "        [-0.0093, -0.0014, -0.0470,  0.0278, -0.0061,  0.0140, -0.0361,  0.0410],\n",
      "        [-0.0209, -0.0069,  0.0148,  0.0327,  0.0167, -0.0581,  0.0144, -0.0368],\n",
      "        [-0.0066, -0.0104,  0.0224, -0.0048,  0.0170, -0.0234,  0.0058, -0.0194],\n",
      "        [-0.0262,  0.0277,  0.0282,  0.0304,  0.0197,  0.0160, -0.0197, -0.0103]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0156, -0.0827,  0.0240,  ..., -0.0040,  0.0078,  0.0482],\n",
       "         [-0.0029, -0.0091,  0.0119,  ..., -0.0888,  0.0161, -0.0760],\n",
       "         [-0.0020, -0.0443, -0.0055,  ..., -0.0038,  0.0613,  0.0669],\n",
       "         ...,\n",
       "         [-0.1265,  0.0414, -0.0365,  ..., -0.0475,  0.0497,  0.0221],\n",
       "         [-0.0841,  0.0131, -0.0475,  ..., -0.0805,  0.1007,  0.0508],\n",
       "         [ 0.1164, -0.0518,  0.0627,  ...,  0.0747, -0.1138, -0.0093]],\n",
       "\n",
       "        [[-0.0765, -0.0879, -0.0052,  ..., -0.1455,  0.1054, -0.0008],\n",
       "         [-0.0434, -0.0662,  0.0277,  ..., -0.1716,  0.0230, -0.0475],\n",
       "         [-0.1141, -0.0538,  0.0278,  ..., -0.1284,  0.0029, -0.0217],\n",
       "         ...,\n",
       "         [-0.0957, -0.0630,  0.0179,  ..., -0.0701,  0.0127,  0.0424],\n",
       "         [-0.1038,  0.0006, -0.0137,  ..., -0.0502,  0.0700,  0.0435],\n",
       "         [-0.0169, -0.0135,  0.0006,  ..., -0.1141, -0.0366, -0.0194]]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction, loss = model.forward(smaller_x, smaller_mask_a, smaller_y)\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_a: tensor([[-0.0269,  0.0067, -0.0262,  0.0040,  0.0176, -0.0387,  0.0145,  0.0043],\n",
      "        [ 0.0308, -0.0302, -0.0117,  0.0023,  0.0023,  0.0229, -0.0437,  0.0015],\n",
      "        [ 0.0349,  0.0124,  0.0028,  0.0099, -0.0156, -0.0413,  0.0263, -0.0152],\n",
      "        [ 0.0394,  0.0131,  0.0221, -0.0006, -0.0446, -0.0309,  0.0073, -0.0035],\n",
      "        [ 0.0177,  0.0008,  0.0347,  0.0450,  0.0025,  0.0206,  0.0017,  0.0077],\n",
      "        [ 0.0374, -0.0081,  0.0181, -0.0004, -0.0102, -0.0009, -0.0017,  0.0089],\n",
      "        [-0.0290,  0.0462, -0.0017, -0.0056,  0.0136, -0.0115, -0.0127,  0.0279],\n",
      "        [ 0.0312, -0.0281,  0.0193, -0.0206,  0.0627,  0.0084,  0.0006, -0.0094],\n",
      "        [-0.0577, -0.0155,  0.0171,  0.0011, -0.0257, -0.0103,  0.0268,  0.0054],\n",
      "        [-0.0076,  0.0290,  0.0289, -0.0381,  0.0088, -0.0141, -0.0454,  0.0172],\n",
      "        [-0.0384, -0.0253,  0.0104,  0.0136,  0.0087, -0.0164,  0.0033, -0.0356],\n",
      "        [-0.0013, -0.0084, -0.0589,  0.0126,  0.0011,  0.0183,  0.0144,  0.0172],\n",
      "        [-0.0096, -0.0215,  0.0417,  0.0044, -0.0113, -0.0227, -0.0135, -0.0238],\n",
      "        [-0.0208,  0.0089,  0.0560, -0.0113,  0.0250, -0.0491, -0.0062, -0.0190],\n",
      "        [-0.0047,  0.0289, -0.0419,  0.0093,  0.0114,  0.0261,  0.0318,  0.0089],\n",
      "        [-0.0224, -0.0083,  0.0010, -0.0590, -0.0597,  0.0488,  0.0859, -0.0018],\n",
      "        [ 0.0096, -0.0183, -0.0129,  0.0102,  0.0179, -0.0546, -0.0336,  0.0091],\n",
      "        [ 0.0296, -0.0238, -0.0051,  0.0231,  0.0117, -0.0054, -0.0421, -0.0343],\n",
      "        [ 0.0156, -0.0347,  0.0258,  0.0563,  0.0221, -0.0171, -0.0188, -0.0359],\n",
      "        [ 0.0341,  0.0201,  0.0200, -0.0071, -0.0177, -0.0511, -0.0352,  0.0333],\n",
      "        [ 0.0012,  0.0427,  0.0323,  0.0321, -0.0147,  0.0172, -0.0141, -0.0057],\n",
      "        [ 0.0150, -0.0047,  0.0345, -0.0022,  0.0016,  0.0065, -0.0172,  0.0279],\n",
      "        [-0.0437,  0.0511, -0.0304,  0.0053,  0.0083, -0.0291,  0.0223,  0.0145],\n",
      "        [ 0.0294,  0.0242,  0.0461, -0.0349,  0.0271, -0.0004, -0.0209,  0.0427],\n",
      "        [-0.0305, -0.0213, -0.0199,  0.0136,  0.0209,  0.0015, -0.0016,  0.0199],\n",
      "        [-0.0090, -0.0126,  0.0283,  0.0020,  0.0128,  0.0057, -0.0070,  0.0361],\n",
      "        [-0.0231, -0.0112,  0.0073,  0.0051, -0.0060, -0.0041,  0.0163,  0.0018],\n",
      "        [-0.0093, -0.0014, -0.0470,  0.0278, -0.0061,  0.0140, -0.0361,  0.0410],\n",
      "        [-0.0209, -0.0069,  0.0148,  0.0327,  0.0167, -0.0581,  0.0144, -0.0368],\n",
      "        [-0.0066, -0.0104,  0.0224, -0.0048,  0.0170, -0.0234,  0.0058, -0.0194],\n",
      "        [-0.0262,  0.0277,  0.0282,  0.0304,  0.0197,  0.0160, -0.0197, -0.0103],\n",
      "        [-0.0111,  0.0217,  0.0250, -0.0187, -0.0424,  0.0349,  0.0507,  0.0025]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0082, -0.0822,  0.0215,  ..., -0.0078,  0.0064,  0.0490],\n",
       "         [ 0.0004, -0.0059,  0.0100,  ..., -0.0888,  0.0163, -0.0763],\n",
       "         [-0.0026, -0.0447, -0.0050,  ..., -0.0035,  0.0609,  0.0667],\n",
       "         ...,\n",
       "         [-0.0841,  0.0130, -0.0474,  ..., -0.0804,  0.1008,  0.0509],\n",
       "         [ 0.1172, -0.0513,  0.0623,  ...,  0.0744, -0.1141, -0.0096],\n",
       "         [ 0.0476,  0.0935, -0.0009,  ...,  0.2191, -0.0713,  0.0294]],\n",
       "\n",
       "        [[-0.0787, -0.0835, -0.0092,  ..., -0.1406,  0.1120,  0.0035],\n",
       "         [-0.0431, -0.0635,  0.0278,  ..., -0.1670,  0.0230, -0.0471],\n",
       "         [-0.1155, -0.0542,  0.0277,  ..., -0.1275,  0.0046, -0.0207],\n",
       "         ...,\n",
       "         [-0.1039,  0.0009, -0.0139,  ..., -0.0501,  0.0702,  0.0435],\n",
       "         [-0.0162, -0.0130,  0.0005,  ..., -0.1137, -0.0368, -0.0196],\n",
       "         [ 0.0532,  0.0948, -0.0191,  ...,  0.1879, -0.0576,  0.0416]]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction, loss = model.forward(x, mask_a, y)\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1240, -0.0138, -0.0116,  ...,  0.0246,  0.0642, -0.0093],\n",
       "         [-0.0308, -0.0465,  0.0618,  ..., -0.0107, -0.0567,  0.0695],\n",
       "         [ 0.1925,  0.0178, -0.0509,  ..., -0.0401, -0.0233, -0.0788],\n",
       "         ...,\n",
       "         [-0.0894,  0.0101,  0.0038,  ...,  0.0319,  0.0619, -0.0301],\n",
       "         [ 0.1274,  0.0194,  0.0573,  ..., -0.0904,  0.0696, -0.0474],\n",
       "         [ 0.0696, -0.0175, -0.0668,  ..., -0.1038,  0.0307,  0.0155]],\n",
       "\n",
       "        [[-0.0419, -0.0668, -0.0014,  ..., -0.0517,  0.0167,  0.0161],\n",
       "         [-0.0791, -0.0336,  0.0591,  ..., -0.0577, -0.0278,  0.0659],\n",
       "         [ 0.2220,  0.0109, -0.0126,  ..., -0.0808,  0.0377, -0.0765],\n",
       "         ...,\n",
       "         [-0.0546,  0.0109,  0.0650,  ...,  0.0655,  0.0622,  0.0057],\n",
       "         [ 0.0643, -0.0055,  0.0791,  ..., -0.0996,  0.0779, -0.0215],\n",
       "         [ 0.0070,  0.0095,  0.0095,  ..., -0.0798,  0.0849,  0.0328]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.contiguous()\n",
    "y = y.contiguous()\n",
    "prediction, loss = gpt_model.forward(x, y)\n",
    "prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0510e-02, -1.4117e-02, -5.6934e-02,  ..., -1.0626e-02,\n",
       "          -8.1248e-03, -4.5611e-02],\n",
       "         [-3.6557e-02, -5.8414e-02, -1.2107e-02,  ...,  3.3612e-02,\n",
       "           3.0184e-02,  1.7920e-02],\n",
       "         [-6.2621e-03, -2.5295e-03, -5.2065e-02,  ...,  3.7995e-02,\n",
       "          -9.1562e-02, -5.6347e-02],\n",
       "         ...,\n",
       "         [-6.3752e-02, -5.7712e-02, -1.8660e-02,  ...,  1.6909e-03,\n",
       "          -5.9226e-02, -5.6394e-03],\n",
       "         [-5.2252e-05, -3.2386e-02,  2.8230e-02,  ..., -2.9082e-02,\n",
       "          -4.6483e-02,  3.5431e-02],\n",
       "         [ 8.1187e-02,  2.7586e-02,  9.1058e-02,  ..., -3.4251e-02,\n",
       "           8.6581e-03,  5.9180e-02]],\n",
       "\n",
       "        [[-5.9181e-02, -6.6251e-02, -4.2869e-02,  ...,  8.1380e-03,\n",
       "           4.2104e-02,  2.5867e-03],\n",
       "         [-2.4729e-02, -3.8237e-02, -1.1000e-01,  ...,  6.5327e-02,\n",
       "           4.9187e-02, -7.3687e-02],\n",
       "         [-1.7524e-02, -2.2506e-02, -5.9681e-02,  ...,  2.2696e-02,\n",
       "          -6.2397e-02, -6.2507e-02],\n",
       "         ...,\n",
       "         [-4.9733e-02, -5.9710e-02,  4.0787e-02,  ..., -3.3379e-02,\n",
       "          -6.4897e-02,  2.9933e-02],\n",
       "         [ 4.9805e-02, -2.4248e-02,  6.3664e-02,  ..., -4.8468e-02,\n",
       "          -6.5503e-02,  3.4298e-02],\n",
       "         [ 8.4615e-02,  2.0896e-02,  6.0511e-02,  ..., -1.9818e-02,\n",
       "          -1.3654e-02,  1.9941e-02]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_small = x[:, :-1].contiguous()\n",
    "y_small = y[:, :-1].contiguous()\n",
    "prediction, loss = gpt_model.forward(x_small, y_small)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
